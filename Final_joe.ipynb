{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joe-P-Pramod/CLASSIFICATION-DRUNK-SOBER-USING-IRIS-PATTERN/blob/main/Final_joe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "L5hDn42nA1yy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0faf8c66-d312-42c9-ff8b-48608dc395ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "M-LIruuU8MwO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oqSVVOQ8UZB",
        "outputId": "4d068630-6e36-4509-895b-339392b93c5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 359 files belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "data = tf.keras.utils.image_dataset_from_directory(\"/content/drive/MyDrive/iris/Iris/Iritech\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "a2slnM6c0lGk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "K582vQui8Yrp"
      },
      "outputs": [],
      "source": [
        "data = data.map(lambda x, y: (x/255, tf.one_hot(y, depth=3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gUy2QN3ztakm"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qD-29oy38b9x"
      },
      "outputs": [],
      "source": [
        "train_size = int(len(data)*.7)\n",
        "val_size = int(len(data)*.2)\n",
        "test_size = int(len(data)*.2)\n",
        "train = data.take(train_size)\n",
        "val = data.skip(train_size).take(val_size)\n",
        "test = data.skip(train_size+val_size).take(test_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "a_DlR3dZvS1v",
        "outputId": "acc008db-b127-4a80-e0eb-7d325b1658c4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Undefined shapes are not supported.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1332742c2dfa>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optree/ops.py\u001b[0m in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0mleaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreespec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_is_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0mflat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_up_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrests\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mflat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Undefined shapes are not supported."
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.applications import ResNet50\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256,256, 3))\n",
        "\n",
        "base_model.trainable = False\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.applications import ResNet50\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256,256, 3))\n",
        "\n",
        "base_model.trainable = False\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "HPODAWhzS4zA",
        "outputId": "ac16341d-8aac-4f71-a4fd-faa0f07e00d9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Undefined shapes are not supported.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-1332742c2dfa>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optree/ops.py\u001b[0m in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0mleaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreespec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_is_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0mflat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_up_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrests\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mflat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Undefined shapes are not supported."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wsNNWoy8hEY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SK4LFVMr0Nri"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOEnqbmy8nMA",
        "outputId": "9859eab5-af50-45ce-b93a-5e3a344f6a03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 123s 2s/step - loss: 6.0714 - accuracy: 0.3906 - val_loss: 2.5705 - val_accuracy: 0.5938\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 4s 416ms/step - loss: 2.1989 - accuracy: 0.3516 - val_loss: 2.0795 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 5s 390ms/step - loss: 1.6736 - accuracy: 0.5078 - val_loss: 1.6073 - val_accuracy: 0.3281\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 4s 363ms/step - loss: 1.1692 - accuracy: 0.4688 - val_loss: 1.0191 - val_accuracy: 0.4531\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 5s 499ms/step - loss: 1.0218 - accuracy: 0.4492 - val_loss: 0.9948 - val_accuracy: 0.4219\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 4s 359ms/step - loss: 0.9885 - accuracy: 0.4492 - val_loss: 0.9188 - val_accuracy: 0.5781\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 4s 362ms/step - loss: 0.9372 - accuracy: 0.6133 - val_loss: 0.8894 - val_accuracy: 0.8594\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 5s 500ms/step - loss: 0.8914 - accuracy: 0.6016 - val_loss: 0.8434 - val_accuracy: 0.8906\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 4s 355ms/step - loss: 0.8776 - accuracy: 0.6797 - val_loss: 0.7937 - val_accuracy: 0.8594\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 4s 362ms/step - loss: 0.8262 - accuracy: 0.6992 - val_loss: 0.7952 - val_accuracy: 0.8438\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 5s 512ms/step - loss: 0.7853 - accuracy: 0.7695 - val_loss: 0.7429 - val_accuracy: 0.8125\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 4s 362ms/step - loss: 0.6949 - accuracy: 0.8008 - val_loss: 0.6445 - val_accuracy: 0.8281\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 4s 362ms/step - loss: 0.6207 - accuracy: 0.7969 - val_loss: 0.6601 - val_accuracy: 0.8125\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 4s 421ms/step - loss: 0.5389 - accuracy: 0.8320 - val_loss: 0.4592 - val_accuracy: 0.8594\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 4s 357ms/step - loss: 0.5092 - accuracy: 0.8242 - val_loss: 0.4474 - val_accuracy: 0.8281\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 4s 368ms/step - loss: 0.4089 - accuracy: 0.8789 - val_loss: 0.3299 - val_accuracy: 0.8438\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 5s 503ms/step - loss: 0.4004 - accuracy: 0.8398 - val_loss: 0.3017 - val_accuracy: 0.8906\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 4s 368ms/step - loss: 0.2936 - accuracy: 0.9023 - val_loss: 0.2381 - val_accuracy: 0.8750\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 4s 357ms/step - loss: 0.3909 - accuracy: 0.8555 - val_loss: 0.1900 - val_accuracy: 0.9531\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 4s 382ms/step - loss: 0.2705 - accuracy: 0.9062 - val_loss: 0.3150 - val_accuracy: 0.8750\n"
          ]
        }
      ],
      "source": [
        "hist = model.fit(train, epochs=20, validation_data=val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fdtS_oojAm8"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjjSh2xt8rdH",
        "outputId": "f2d225d1-778f-433f-b7ab-77c76adfdf8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 4s 1s/step - loss: 0.2834 - accuracy: 0.8718\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.28342363238334656, 0.8717948794364929]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model.evaluate(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkJQC-tf8tzG",
        "outputId": "6db8b2af-5f82-42cf-bd28-5509d6cfb1f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2go2Idi0ezJk"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "def convert_to_nir(image):\n",
        "    nir_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    nir_image = np.stack((nir_image,) * 3, axis=-1)\n",
        "    return nir_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhQuVMFvgD3T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "9ccb7a0f-8576-40d3-cd2d-6f8a1cff0992"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6180807d2459>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnir_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_nir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-12cf26f31ca6>\u001b[0m in \u001b[0;36mconvert_to_nir\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_nir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mnir_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mnir_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnir_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnir_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ],
      "source": [
        "input_image_path = \"drunk_image.png\"\n",
        "input_image = cv2.imread(input_image_path)\n",
        "image = cv2.imread(input_image_path)\n",
        "\n",
        "nir_image = convert_to_nir(input_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtcurF7KezJn"
      },
      "outputs": [],
      "source": [
        "input_image_path = \"eye.png\"\n",
        "input_image = cv2.imread(input_image_path)\n",
        "image = cv2.imread(input_image_path)\n",
        "\n",
        "nir_image = convert_to_nir(input_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUoQX70rWcdU"
      },
      "outputs": [],
      "source": [
        "input_image_path = \"drunk1.bmp\"\n",
        "input_image = cv2.imread(input_image_path)\n",
        "image = cv2.imread(input_image_path)\n",
        "\n",
        "nir_image = convert_to_nir(input_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RUprzVNXSQr"
      },
      "outputs": [],
      "source": [
        "input_image_path = \"normal1.bmp\"\n",
        "input_image = cv2.imread(input_image_path)\n",
        "image = cv2.imread(input_image_path)\n",
        "\n",
        "nir_image = convert_to_nir(input_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OcctD1lhFTA"
      },
      "outputs": [],
      "source": [
        "input_image_path = \"normal_4.png\"\n",
        "input_image = cv2.imread(input_image_path)\n",
        "image = cv2.imread(input_image_path)\n",
        "\n",
        "nir_image = convert_to_nir(input_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqLoDx59ezJo"
      },
      "outputs": [],
      "source": [
        "plt.imshow(nir_image.astype(np.uint8))\n",
        "plt.title('NIR Image')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DryV6izezJq"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('model.h5')\n",
        "def preprocess_image(image):\n",
        "    resized_image = cv2.resize(image, (256, 256))\n",
        "    normalized_image = resized_image / 255.0\n",
        "    input_image = np.expand_dims(normalized_image, axis=0)\n",
        "    return input_image\n",
        "input_image = preprocess_image(nir_image)\n",
        "value = model.predict(input_image)\n",
        "value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWy5OOsWpkgJ"
      },
      "outputs": [],
      "source": [
        "prediction = np.argmax(value)\n",
        "if prediction ==0:\n",
        "    print('Sober')\n",
        "elif prediction == 1:\n",
        "    print('Drunk_30min')\n",
        "else:\n",
        "    print('Drunk_60min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmwyHi-SzC4a",
        "outputId": "3b70801d-8c41-4451-88a7-d9837c9af673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "# Streamlit app\n",
        "import streamlit as st\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/model.h5')\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def load_image(uploaded_file):\n",
        "    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)\n",
        "    input_image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
        "    nir_image = convert_to_nir(input_image)\n",
        "    return nir_image\n",
        "\n",
        "\n",
        "def convert_to_nir(image):\n",
        "    nir_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    nir_image = np.stack((nir_image,) * 3, axis=-1)\n",
        "    return nir_image\n",
        "\n",
        "\n",
        "def preprocess_image(image):\n",
        "    resized_image = cv2.resize(image, (256, 256))\n",
        "    normalized_image = resized_image / 255.0\n",
        "    input_image = np.expand_dims(normalized_image, axis=0)\n",
        "    return input_image\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    st.title(\"Drunk Detection\")\n",
        "\n",
        "    # Upload Image\n",
        "    uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\",\"bmp\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        custom_image = load_image(uploaded_file)\n",
        "\n",
        "        # Display uploaded image\n",
        "        st.image(custom_image, caption='Uploaded Image.', use_column_width=True)\n",
        "        if st.button(\"Predict\"):\n",
        "            nir_image = convert_to_nir(custom_image)\n",
        "            input_image = preprocess_image(nir_image)\n",
        "            value = model.predict(input_image)\n",
        "            prediction = np.argmax(value)\n",
        "            if prediction ==0:\n",
        "                predicted_answer = 'Sober'\n",
        "            elif prediction == 1:\n",
        "                predicted_answer ='Drunk_30min'\n",
        "            else:\n",
        "                predicted_answer = 'Drunk_60min'\n",
        "            st.success(\"Predicted Answer: {}\".format(predicted_answer))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC1ANVnE_WlZ"
      },
      "source": [
        " **Streamlit working**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jasoa0gY06Gt",
        "outputId": "52c3a774-9f7f-4a65-a2dc-11bc2f8b125b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install streamlit -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIV1II9d1vxb",
        "outputId": "f2a2d938-0e88-4540-8f9f-1b28d5a17828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.240.193.48\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx8a7k_q4tDg",
        "outputId": "c84487bc-aee4-44b1-f586-97f513125f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.240.193.48:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 1.97s\n",
            "your url is: https://new-sites-show.loca.lt\n",
            "2024-07-19 07:49:57.075232: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-19 07:49:57.075296: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-19 07:49:57.076734: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-19 07:49:58.315288: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-07-19 07:50:00.712677: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2024-07-19 07:50:30.569703: W external/local_tsl/tsl/framework/bfc_allocator.cc:366] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 1s 909ms/step\n"
          ]
        }
      ],
      "source": [
        "! streamlit run app.py & npx localtunnel --port 8501\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbpQYUjh7uMD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}